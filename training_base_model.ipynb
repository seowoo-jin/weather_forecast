{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "# MLP 모델 정의\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_size, hidden_layers, output_size):\n",
    "        super(MLP, self).__init__()\n",
    "        layers = []\n",
    "        in_size = input_size\n",
    "        for h in hidden_layers:\n",
    "            layers.append(nn.Linear(in_size, h))\n",
    "            layers.append(nn.ReLU())\n",
    "            in_size = h\n",
    "        layers.append(nn.Linear(in_size, output_size))\n",
    "        self.network = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.network(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "import xgboost\n",
    "\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "from utils.weather_api import WeatherApi\n",
    "from utils.common_function import splitData\n",
    "from enums.enums import Model, Date, Data, Rmse\n",
    "\n",
    "weatherApi = WeatherApi();\n",
    "area = 'Swanton_OH'\n",
    "# Swanton_OH\n",
    "X, y = weatherApi.get_weather_data_from_excel(area)\n",
    "X_train, X_test, y_train, y_test = splitData(X, y, 365)\n",
    "\n",
    "# MinMaxScaler 적용\n",
    "scaler = MinMaxScaler()\n",
    "if 'date' in X_train.columns:\n",
    "    X_train = X_train.drop(columns=['date'])\n",
    "    X_test = X_test.drop(columns=['date'])\n",
    "if 'date' in y_train.columns[0]:\n",
    "    y_train = y_train.drop(columns=[y_train.columns[0]])\n",
    "    y_test = y_test.drop(columns=[y_test.columns[0]])\n",
    "\n",
    "# MinMaxScaler 적용\n",
    "X_train_scaled = pd.DataFrame(scaler.fit_transform(X_train), columns=X_train.columns)\n",
    "X_test_scaled = pd.DataFrame(scaler.transform(X_test), columns=X_test.columns)\n",
    "\n",
    "date_range = pd.date_range(start='2023-08-01', end='2024-07-30')\n",
    "date_df = pd.DataFrame(date_range, columns=['date'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RandomForest 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\SW\\Documents\\projects\\wf\\weather_forecast\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:540: FitFailedWarning: \n",
      "450 fits failed out of a total of 2250.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "450 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\SW\\Documents\\projects\\wf\\weather_forecast\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\SW\\Documents\\projects\\wf\\weather_forecast\\venv\\Lib\\site-packages\\sklearn\\base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\SW\\Documents\\projects\\wf\\weather_forecast\\venv\\Lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\SW\\Documents\\projects\\wf\\weather_forecast\\venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'min_samples_split' parameter of RandomForestRegressor must be an int in the range [2, inf) or a float in the range (0.0, 1.0]. Got 1 instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\SW\\Documents\\projects\\wf\\weather_forecast\\venv\\Lib\\site-packages\\numpy\\ma\\core.py:2846: RuntimeWarning: invalid value encountered in cast\n",
      "  _data = np.array(data, dtype=dtype, copy=copy,\n",
      "c:\\Users\\SW\\Documents\\projects\\wf\\weather_forecast\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1102: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan 0.78098869 0.78147451 0.78176267\n",
      " 0.78099495 0.78147756 0.78176409 0.78099546 0.78147237 0.78175896\n",
      " 0.78099185 0.78147347 0.7817589         nan        nan        nan\n",
      " 0.78116798 0.78162789 0.78191692 0.78116798 0.78162789 0.78191692\n",
      " 0.78117117 0.78162883 0.78191525 0.78117144 0.78162206 0.78191184\n",
      "        nan        nan        nan 0.78120993 0.78168243 0.78198302\n",
      " 0.78120993 0.78168243 0.78198302 0.78120993 0.78168243 0.78198302\n",
      " 0.78120993 0.78168243 0.78198302        nan        nan        nan\n",
      " 0.78122863 0.78163055 0.78190559 0.78122863 0.78163055 0.78190559\n",
      " 0.78122863 0.78163055 0.78190559 0.78122863 0.78163055 0.78190559\n",
      "        nan        nan        nan 0.78121384 0.78157813 0.78190544\n",
      " 0.78121384 0.78157813 0.78190544 0.78121384 0.78157813 0.78190544\n",
      " 0.78121384 0.78157813 0.78190544        nan        nan        nan\n",
      " 0.83398572 0.83529722 0.83588921 0.83349934 0.83477924 0.83516383\n",
      " 0.83307171 0.83446778 0.83490906 0.83225641 0.83346458 0.83396812\n",
      "        nan        nan        nan 0.83341182 0.8347168  0.83523034\n",
      " 0.83341182 0.8347168  0.83523034 0.8332524  0.83456221 0.83507579\n",
      " 0.8322523  0.83360885 0.83403919        nan        nan        nan\n",
      " 0.83132656 0.83222545 0.83263888 0.83132656 0.83222545 0.83263888\n",
      " 0.83132656 0.83222545 0.83263888 0.83132656 0.83222545 0.83263888\n",
      "        nan        nan        nan 0.82822749 0.8288373  0.82916467\n",
      " 0.82822749 0.8288373  0.82916467 0.82822749 0.8288373  0.82916467\n",
      " 0.82822749 0.8288373  0.82916467        nan        nan        nan\n",
      " 0.82486553 0.82543616 0.82581633 0.82486553 0.82543616 0.82581633\n",
      " 0.82486553 0.82543616 0.82581633 0.82486553 0.82543616 0.82581633\n",
      "        nan        nan        nan 0.83660136 0.83758539 0.83804458\n",
      " 0.83539063 0.83680503 0.83719528 0.83441042 0.83561915 0.83630009\n",
      " 0.83368864 0.83492133 0.83532125        nan        nan        nan\n",
      " 0.83461995 0.83599877 0.83650868 0.83461995 0.83599877 0.83650868\n",
      " 0.83447874 0.83571024 0.83621359 0.83345399 0.83467835 0.8351411\n",
      "        nan        nan        nan 0.83192026 0.83284272 0.83324779\n",
      " 0.83192026 0.83284272 0.83324779 0.83192026 0.83284272 0.83324779\n",
      " 0.83192026 0.83284272 0.83324779        nan        nan        nan\n",
      " 0.82852813 0.82914527 0.82945357 0.82852813 0.82914527 0.82945357\n",
      " 0.82852813 0.82914527 0.82945357 0.82852813 0.82914527 0.82945357\n",
      "        nan        nan        nan 0.82497323 0.8255331  0.82592461\n",
      " 0.82497323 0.8255331  0.82592461 0.82497323 0.8255331  0.82592461\n",
      " 0.82497323 0.8255331  0.82592461]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    params = {\n",
    "        'n_estimators':(100, 200, 300),\n",
    "        'max_depth' : (5, 10, 15),\n",
    "        'min_samples_leaf' : (1, 3, 5, 7, 9),\n",
    "        'min_samples_split' : (1, 3, 5, 7, 9)\n",
    "    }\n",
    "\n",
    "    rf = RandomForestRegressor(random_state=0)\n",
    "    rf_model = GridSearchCV(estimator=rf, param_grid=params, cv=10, n_jobs=-1)\n",
    "    rf_model_result = rf_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "    rf_best_model = rf_model_result.best_estimator_\n",
    "    rf_predict = rf_best_model.predict(X_test_scaled)\n",
    "\n",
    "    data_to_save = {\n",
    "        Model.MODEL.value: rf_best_model,\n",
    "        Data.TRAIN_INPUT_DATA.value: X_train_scaled,\n",
    "        Data.TRAIN_OUTPUT_DATA.value: X_test_scaled,\n",
    "        Data.VALID_INPUT_DATA.value: [],\n",
    "        Data.VALID_OUTPUT_DATA.value: [],\n",
    "        Data.TEST_INPUT_DATA.value: y_train,\n",
    "        Data.TEST_OUTPUT_DATA.value: y_test,\n",
    "        Data.PREDICTED_OUTPUT_DATA.value: pd.DataFrame(rf_predict, columns=y_test.columns),\n",
    "        Rmse.BEST_RMSE.value: math.sqrt(mean_squared_error(rf_predict, y_test.to_numpy())),\n",
    "        Date.DATE.value: date_df\n",
    "    }\n",
    "\n",
    "    path = f'result_model/{area}'\n",
    "    file_path = f'{path}/RF_model_with_{area}.pkl'\n",
    "\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "    with open(file_path, 'wb') as f:\n",
    "        pickle.dump(data_to_save, f)\n",
    "except Exception as e:\n",
    "    print(f\"오류 발생: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MLP 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "오류 발생: module 'torch' has no attribute 'version'\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    scaler = MinMaxScaler()\n",
    "    X_train_mlp_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_mlp_scaled = scaler.transform(X_test)\n",
    "\n",
    "    X_train_tensor = torch.tensor(X_train_mlp_scaled, dtype=torch.float32)\n",
    "    y_train_tensor = torch.tensor(y_train.values, dtype=torch.float32)\n",
    "    test_dataset = TensorDataset(torch.tensor(X_test_mlp_scaled, dtype=torch.float32), torch.tensor(y_test.values, dtype=torch.float32))\n",
    "    test_loader = DataLoader(test_dataset, batch_size=5, shuffle=False)\n",
    "\n",
    "    min_i_value = 0\n",
    "    min_j_value = 0\n",
    "    mlp_best_rmse = 100\n",
    "    # 최적 모델 구성에서 사용된 데이터 저장 변수 초기화\n",
    "    best_train_input_data = None\n",
    "    best_train_output_data = None\n",
    "    best_valid_input_data = None\n",
    "    best_valid_output_data = None\n",
    "    best_test_input_data = None\n",
    "    best_test_output_data = None\n",
    "    best_valid_predictions = None\n",
    "    best_test_predictions = None\n",
    "    mlp_best_rmse = float('inf')\n",
    "\n",
    "    moving_valid_rmse = []\n",
    "    moving_test_rmse = []\n",
    "    mlp_best_model = None\n",
    "\n",
    "    kf = KFold(n_splits=10, shuffle=False)\n",
    "    for fold, (train_index, valid_index) in enumerate(kf.split(X_train_mlp_scaled)):\n",
    "\n",
    "        # Split the data\n",
    "        X_train_fold, X_valid_fold = X_train_tensor[train_index], X_train_tensor[valid_index]\n",
    "        y_train_fold, y_valid_fold = y_train_tensor[train_index], y_train_tensor[valid_index]\n",
    "\n",
    "        # TensorDataset, DataLoader로 변경\n",
    "        train_dataset = TensorDataset(X_train_fold, y_train_fold)\n",
    "        valid_dataset = TensorDataset(X_valid_fold, y_valid_fold)\n",
    "        train_loader = DataLoader(train_dataset, batch_size=3, shuffle=True)\n",
    "        valid_loader = DataLoader(valid_dataset, batch_size=3, shuffle=False)\n",
    "\n",
    "        for i in [64, 128, 256, 512]:\n",
    "            for j in  [4, 8, 16, 32, 63]:\n",
    "                if(i > j):\n",
    "                    model = MLP(input_size=len(X_train.columns), hidden_layers=[i, j], output_size=len(y_train.columns))\n",
    "                    criterion = nn.MSELoss()\n",
    "                    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "                    num_epochs = 1000\n",
    "                    best_loss = float('inf')\n",
    "                    epochs_no_improve = 0\n",
    "                    early_stop = False\n",
    "                    print(f'processing start with fold in {fold}, i in {i} and j in {j}')\n",
    "                    for epoch in range(num_epochs):\n",
    "                        model.train()\n",
    "                        for inputs, labels in train_loader:\n",
    "                            optimizer.zero_grad()\n",
    "                            outputs = model(inputs)\n",
    "                            loss = criterion(outputs, labels)\n",
    "                            loss.backward()\n",
    "                            optimizer.step()\n",
    "\n",
    "                        # Early stopping\n",
    "                        model.eval()\n",
    "                        val_loss = 0\n",
    "                        with torch.no_grad():\n",
    "                            for inputs, labels in valid_loader:\n",
    "                                outputs = model(inputs)\n",
    "                                val_loss += criterion(outputs, labels).item()\n",
    "\n",
    "                        val_loss /= len(valid_loader)\n",
    "\n",
    "                        # print(f'Epoch {epoch+1}/{num_epochs}, Loss: {loss.item()}, Val Loss: {val_loss}')\n",
    "\n",
    "                        # 연속적으로 best_loss보다 개선되지 않는 횟수\n",
    "                        if val_loss < best_loss:\n",
    "                            best_loss = val_loss\n",
    "                            epochs_no_improve = 0\n",
    "                        else:\n",
    "                            epochs_no_improve += 1\n",
    "                        # patience만큼 개선이 없으면 종료\n",
    "                        if epochs_no_improve >= 50:\n",
    "                            print(f'Early stopping after {epoch+1} epochs')\n",
    "                            early_stop = True\n",
    "                            break\n",
    "                                # Model evaluation\n",
    "\n",
    "                    model.eval()\n",
    "                    valid_predictions = []\n",
    "                    valid_true_values = []\n",
    "                    with torch.no_grad():\n",
    "                        for inputs, labels in valid_loader:\n",
    "                            outputs = model(inputs)\n",
    "                            valid_predictions.append(outputs.numpy())\n",
    "                            valid_true_values.append(labels.numpy())\n",
    "\n",
    "                    valid_predictions = np.vstack(valid_predictions)\n",
    "                    valid_true_values = np.vstack(valid_true_values)\n",
    "\n",
    "                    valid_rmse = mean_squared_error(valid_true_values, valid_predictions, squared=True)\n",
    "                    moving_valid_rmse.append(valid_rmse)\n",
    "                    if(mlp_best_rmse > valid_rmse):\n",
    "                        mlp_best_model = model\n",
    "                        mlp_best_rmse = valid_rmse\n",
    "                        test_predictions = []\n",
    "                        test_true_values = []\n",
    "\n",
    "                        with torch.no_grad():\n",
    "                            for inputs, labels in test_loader:\n",
    "                                outputs = model(inputs)\n",
    "                                test_predictions.append(outputs.numpy())\n",
    "                                test_true_values.append(labels.numpy())\n",
    "                        test_predictions = np.vstack(test_predictions)\n",
    "                        test_true_values = np.vstack(test_true_values)\n",
    "                        test_rmse = mean_squared_error(test_true_values, test_predictions, squared=False)\n",
    "                        best_train_input_data = pd.DataFrame(train_dataset.tensors[0].numpy(), columns=[f'{i}' for i in X.columns])\n",
    "                        best_train_output_data = pd.DataFrame(train_dataset.tensors[1].numpy(), columns=[f'{i}' for i in y.columns])\n",
    "                        best_valid_input_data = pd.DataFrame(valid_dataset.tensors[0].numpy(), columns=[f'{i}' for i in X.columns])\n",
    "                        best_valid_output_data = pd.DataFrame(valid_dataset.tensors[1].numpy(), columns=[f'{i}' for i in y.columns])\n",
    "                        best_test_input_data = pd.DataFrame(test_dataset.tensors[0].numpy(), columns=[f'{i}' for i in X.columns])\n",
    "                        best_test_output_data = pd.DataFrame(test_dataset.tensors[1].numpy(), columns=[f'{i}' for i in y.columns])\n",
    "                        best_test_predictions = pd.DataFrame(test_predictions, columns=[f'{i}' for i in y.columns])\n",
    "\n",
    "                        print(f'first node : {i}, snd node : {j},  fold : {fold}, valid_rmse : {valid_rmse}, test_rmse : {test_rmse}')\n",
    "                    print(f'processing end with  fold in {fold} i in {i} and j in {j}')\n",
    "\n",
    "    data_to_save = {\n",
    "        Model.MODEL.value: mlp_best_model,\n",
    "        Data.TRAIN_INPUT_DATA.value: best_train_input_data,\n",
    "        Data.TRAIN_OUTPUT_DATA.value: best_train_output_data,\n",
    "        Data.VALID_INPUT_DATA.value: best_valid_input_data,\n",
    "        Data.VALID_OUTPUT_DATA.value: best_valid_output_data,\n",
    "        Data.TEST_INPUT_DATA.value: best_test_input_data,\n",
    "        Data.TEST_OUTPUT_DATA.value: best_test_output_data,\n",
    "        Data.PREDICTED_OUTPUT_DATA.value: best_test_predictions,\n",
    "        Rmse.BEST_RMSE: mlp_best_rmse,\n",
    "        Date.DATE.value: date_df,\n",
    "    }\n",
    "\n",
    "    path = f'result_model/{area}'\n",
    "    file_path = f'{path}/MLP_model_with_{area}.pkl'\n",
    "\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "    with open(file_path, 'wb') as f:\n",
    "        pickle.dump(data_to_save, f)\n",
    "except Exception as e:\n",
    "    print(f\"오류 발생: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adaboost 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\SW\\Documents\\projects\\wf\\weather_forecast\\venv\\Lib\\site-packages\\numpy\\ma\\core.py:2846: RuntimeWarning: invalid value encountered in cast\n",
      "  _data = np.array(data, dtype=dtype, copy=copy,\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    param_grid = {\n",
    "        'estimator__n_estimators': [50, 100, 150, 200],\n",
    "        'estimator__learning_rate': [0.1, 0.3, 0.5, 0.7],\n",
    "        'estimator__estimator__max_depth': [2, 4, 8, 16, 32, 64]\n",
    "    }\n",
    "\n",
    "    base_ada = AdaBoostRegressor(estimator=DecisionTreeRegressor())\n",
    "    fit_model = MultiOutputRegressor(base_ada)\n",
    "\n",
    "    adaboost_model = GridSearchCV(estimator=fit_model, param_grid=param_grid, cv=10)\n",
    "    adaboost_model_result = adaboost_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "    Adaboost_best_model = adaboost_model_result.best_estimator_\n",
    "\n",
    "    Adaboost_predictions = Adaboost_best_model.predict(X_test)\n",
    "\n",
    "    # Calculate and print RMSE\n",
    "    Adaboost_best_rmse = math.sqrt(mean_squared_error(y_test, Adaboost_predictions))\n",
    "\n",
    "    data_to_save = {\n",
    "        Model.MODEL.value: Adaboost_best_model,\n",
    "        Data.TRAIN_INPUT_DATA.value: X_train_scaled,\n",
    "        Data.TRAIN_OUTPUT_DATA.value: X_test_scaled,\n",
    "        Data.VALID_INPUT_DATA.value: [],\n",
    "        Data.VALID_OUTPUT_DATA.value: [],\n",
    "        Data.TEST_INPUT_DATA.value: y_train,\n",
    "        Data.TEST_OUTPUT_DATA.value: y_test,\n",
    "        Data.PREDICTED_OUTPUT_DATA.value: Adaboost_predictions,\n",
    "        Rmse.BEST_RMSE: Adaboost_best_rmse,\n",
    "        Date.DATE.value: date_df,\n",
    "    }\n",
    "\n",
    "    path = f'result_model/{area}'\n",
    "    file_path = f'{path}/Adaboost_model_with_{area}.pkl'\n",
    "\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "    with open(file_path, 'wb') as f:\n",
    "        pickle.dump(data_to_save, f)\n",
    "except Exception as e:\n",
    "    print(f\"오류 발생: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DecisionTree 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\SW\\Documents\\projects\\wf\\weather_forecast\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:540: FitFailedWarning: \n",
      "240 fits failed out of a total of 960.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "240 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\SW\\Documents\\projects\\wf\\weather_forecast\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\SW\\Documents\\projects\\wf\\weather_forecast\\venv\\Lib\\site-packages\\sklearn\\base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\SW\\Documents\\projects\\wf\\weather_forecast\\venv\\Lib\\site-packages\\sklearn\\pipeline.py\", line 473, in fit\n",
      "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
      "  File \"c:\\Users\\SW\\Documents\\projects\\wf\\weather_forecast\\venv\\Lib\\site-packages\\sklearn\\base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\SW\\Documents\\projects\\wf\\weather_forecast\\venv\\Lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1377, in fit\n",
      "    super()._fit(\n",
      "  File \"c:\\Users\\SW\\Documents\\projects\\wf\\weather_forecast\\venv\\Lib\\site-packages\\sklearn\\tree\\_classes.py\", line 269, in _fit\n",
      "    raise ValueError(\n",
      "ValueError: Some value(s) of y are negative which is not allowed for Poisson regression.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\SW\\Documents\\projects\\wf\\weather_forecast\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1102: UserWarning: One or more of the test scores are non-finite: [-30.3173589  -30.3173589  -30.3173589  -30.3173589  -22.46614355\n",
      " -22.46614355 -22.39019821 -22.36512031 -19.16113235 -18.55483587\n",
      " -18.3602278  -18.38719356 -20.22941129 -18.66358762 -18.21259502\n",
      " -18.36824896 -20.20163862 -18.66358762 -18.21259502 -18.36824896\n",
      " -20.20163862 -18.66358762 -18.21259502 -18.36824896 -30.19886436\n",
      " -30.19886436 -30.19886436 -30.19886436 -21.79485253 -21.79485253\n",
      " -21.79485253 -21.79485253 -18.77444267 -18.1494274  -17.70731735\n",
      " -17.8486948  -19.74292182 -18.33557005 -17.55079227 -17.86853837\n",
      " -19.74292182 -18.33557005 -17.55079227 -17.86853837 -19.74292182\n",
      " -18.33557005 -17.55079227 -17.86853837          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan -29.77924725 -29.77924725 -29.77924725\n",
      " -29.77924725 -21.06143994 -21.06143994 -21.06143994 -21.06143994\n",
      " -18.49342889 -17.66738386 -17.5960869  -17.37452321 -19.79432014\n",
      " -17.94273897 -17.6030811  -17.38787733 -19.79432014 -17.94273897\n",
      " -17.6030811  -17.38787733 -19.79432014 -17.94273897 -17.6030811\n",
      " -17.38787733]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    pipe_tree = make_pipeline(DecisionTreeRegressor(random_state=2021))\n",
    "    # 트리의 파라미터 키값 확인\n",
    "    pipe_tree.get_params().keys()\n",
    "\n",
    "    param_range1 = [2, 4, 8, 16, 32, 64]\n",
    "    param_range2 = [5, 10, 15, 20]\n",
    "    param_range3 = ['friedman_mse', 'absolute_error', 'poisson', 'squared_error'] # 'explained_variance'도 가능\n",
    "\n",
    "    param_grid = [{'decisiontreeregressor__max_depth': param_range1,\n",
    "                'decisiontreeregressor__min_samples_leaf': param_range2,\n",
    "                'decisiontreeregressor__criterion': param_range3}]\n",
    "\n",
    "    decisionTree_model = GridSearchCV(\n",
    "        estimator = pipe_tree,\n",
    "        param_grid = param_grid,\n",
    "        scoring = 'neg_mean_squared_error',\n",
    "        n_jobs= -1,\n",
    "        cv=10\n",
    "    )\n",
    "\n",
    "    decisionTree_model_result = decisionTree_model.fit(X_train_scaled, y_train)\n",
    "    decisionTree_best_model = decisionTree_model_result.best_estimator_\n",
    "\n",
    "    decisionTree__pred = decisionTree_best_model.predict(X_test_scaled)\n",
    "\n",
    "    data_to_save = {\n",
    "        Model.MODEL.value: decisionTree_best_model,\n",
    "        Data.TRAIN_INPUT_DATA.value: X_train_scaled,\n",
    "        Data.TRAIN_OUTPUT_DATA.value: X_test_scaled,\n",
    "        Data.VALID_INPUT_DATA.value: [],\n",
    "        Data.VALID_OUTPUT_DATA.value: [],\n",
    "        Data.TEST_INPUT_DATA.value: y_train,\n",
    "        Data.TEST_OUTPUT_DATA.value: y_test,\n",
    "        Data.PREDICTED_OUTPUT_DATA.value: decisionTree__pred,\n",
    "        Rmse.BEST_RMSE: math.sqrt(mean_squared_error(decisionTree__pred, y_test)),\n",
    "        Date.DATE.value: date_df,\n",
    "    }\n",
    "\n",
    "    path = f'result_model/{area}'\n",
    "    file_path = f'{path}/DecisionTree_model_with_{area}.pkl'\n",
    "\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "    with open(file_path, 'wb') as f:\n",
    "        pickle.dump(data_to_save, f)\n",
    "except Exception as e:\n",
    "    print(f\"오류 발생: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ExtraTree 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    tunning_model = ExtraTreesRegressor()\n",
    "    gsc = GridSearchCV(\n",
    "        estimator=tunning_model,\n",
    "        param_grid={\n",
    "            'n_estimators': range(100, 400, 100),\n",
    "            'max_features': range(5,20,5),\n",
    "            'min_samples_leaf': range(5,20,5),\n",
    "            'min_samples_split': range(5,20,5),\n",
    "        },\n",
    "        cv=10\n",
    "    )\n",
    "    extra_best_model_result = gsc.fit(X_train_scaled.to_numpy(), y_train.to_numpy())\n",
    "    extra_best_model = extra_best_model_result.best_estimator_\n",
    "\n",
    "    extra_best_prediction = extra_best_model.predict(X_test_scaled.to_numpy())\n",
    "\n",
    "    data_to_save = {\n",
    "        Model.MODEL.value: extra_best_model,\n",
    "        Data.TRAIN_INPUT_DATA.value: X_train_scaled,\n",
    "        Data.TRAIN_OUTPUT_DATA.value: X_test_scaled,\n",
    "        Data.VALID_INPUT_DATA.value: [],\n",
    "        Data.VALID_OUTPUT_DATA.value: [],\n",
    "        Data.TEST_INPUT_DATA.value: y_train,\n",
    "        Data.TEST_OUTPUT_DATA.value: y_test,\n",
    "        Data.PREDICTED_OUTPUT_DATA.value: extra_best_prediction,\n",
    "        Rmse.BEST_RMSE: math.sqrt(mean_squared_error(extra_best_prediction, y_test)),\n",
    "        Date.DATE.value: date_df,\n",
    "    }\n",
    "\n",
    "    path = f'result_model/{area}'\n",
    "    file_path = f'{path}/ExtraTree_model_with_{area}.pkl'\n",
    "\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "    with open(file_path, 'wb') as f:\n",
    "        pickle.dump(data_to_save, f)\n",
    "except Exception as e:\n",
    "    print(f\"오류 발생: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GradientBoosting 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "오류 발생: Invalid parameter 'max_depth' for estimator MultiOutputRegressor(estimator=GradientBoostingRegressor()). Valid parameters are: ['estimator', 'n_jobs'].\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    gradientBoosting = GradientBoostingRegressor()\n",
    "\n",
    "    param_grid = {\n",
    "        'n_estimators': [100, 200, 300, 500],\n",
    "        'max_depth': [2, 4, 8, 16, 32],\n",
    "        'min_samples_split': [2, 4, 8, 16, 32],\n",
    "        'min_samples_leaf': [2, 4, 8, 16, 32]\n",
    "    }\n",
    "    gradientBoosting_model_result = GridSearchCV(\n",
    "        MultiOutputRegressor(gradientBoosting),\n",
    "        param_grid,\n",
    "        scoring='neg_mean_squared_error',\n",
    "        cv=10,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    gradientBoosting_model_result.fit(X_train_scaled, y_train)\n",
    "    gradientBoosting_best_model = gradientBoosting_model_result.best_estimator_\n",
    "\n",
    "    gradientBoosting_predictions = gradientBoosting_best_model.predict(X_test_scaled)\n",
    "\n",
    "    # Save the results\n",
    "    data_to_save = {\n",
    "        Model.MODEL.value: gradientBoosting_best_model,\n",
    "        Data.TRAIN_INPUT_DATA.value: X_train_scaled,\n",
    "        Data.TRAIN_OUTPUT_DATA.value: y_train,\n",
    "        Data.VALID_INPUT_DATA.value: [],\n",
    "        Data.VALID_OUTPUT_DATA.value: [],\n",
    "        Data.TEST_INPUT_DATA.value: X_test_scaled,\n",
    "        Data.TEST_OUTPUT_DATA.value: y_test,\n",
    "        Data.PREDICTED_OUTPUT_DATA.value: gradientBoosting_predictions,\n",
    "        Rmse.BEST_RMSE: math.sqrt(mean_squared_error(y_test, gradientBoosting_predictions)),\n",
    "        Date.DATE.value: date_df,\n",
    "    }\n",
    "\n",
    "    path = f'result_model/{area}'\n",
    "    file_path = f'{path}/GradientBoosting_model_with_{area}.pkl'\n",
    "\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "    with open(file_path, 'wb') as f:\n",
    "        pickle.dump(data_to_save, f)\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"오류 발생: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Xgboost 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "오류 발생: \n",
      "All the 750 fits failed.\n",
      "It is very likely that your model is misconfigured.\n",
      "You can try to debug the error by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "150 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\SW\\Documents\\projects\\wf\\weather_forecast\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\SW\\Documents\\projects\\wf\\weather_forecast\\venv\\Lib\\site-packages\\xgboost\\core.py\", line 726, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\SW\\Documents\\projects\\wf\\weather_forecast\\venv\\Lib\\site-packages\\xgboost\\sklearn.py\", line 1108, in fit\n",
      "    self._Booster = train(\n",
      "                    ^^^^^^\n",
      "  File \"c:\\Users\\SW\\Documents\\projects\\wf\\weather_forecast\\venv\\Lib\\site-packages\\xgboost\\core.py\", line 726, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\SW\\Documents\\projects\\wf\\weather_forecast\\venv\\Lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"c:\\Users\\SW\\Documents\\projects\\wf\\weather_forecast\\venv\\Lib\\site-packages\\xgboost\\core.py\", line 2100, in update\n",
      "    _check_call(\n",
      "  File \"c:\\Users\\SW\\Documents\\projects\\wf\\weather_forecast\\venv\\Lib\\site-packages\\xgboost\\core.py\", line 284, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 2 for Parameter colsample_bytree exceed bound [0,1]\n",
      "colsample_bytree: Subsample ratio of columns, resample on each tree construction.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "150 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\SW\\Documents\\projects\\wf\\weather_forecast\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\SW\\Documents\\projects\\wf\\weather_forecast\\venv\\Lib\\site-packages\\xgboost\\core.py\", line 726, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\SW\\Documents\\projects\\wf\\weather_forecast\\venv\\Lib\\site-packages\\xgboost\\sklearn.py\", line 1108, in fit\n",
      "    self._Booster = train(\n",
      "                    ^^^^^^\n",
      "  File \"c:\\Users\\SW\\Documents\\projects\\wf\\weather_forecast\\venv\\Lib\\site-packages\\xgboost\\core.py\", line 726, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\SW\\Documents\\projects\\wf\\weather_forecast\\venv\\Lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"c:\\Users\\SW\\Documents\\projects\\wf\\weather_forecast\\venv\\Lib\\site-packages\\xgboost\\core.py\", line 2100, in update\n",
      "    _check_call(\n",
      "  File \"c:\\Users\\SW\\Documents\\projects\\wf\\weather_forecast\\venv\\Lib\\site-packages\\xgboost\\core.py\", line 284, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 4 for Parameter colsample_bytree exceed bound [0,1]\n",
      "colsample_bytree: Subsample ratio of columns, resample on each tree construction.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "150 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\SW\\Documents\\projects\\wf\\weather_forecast\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\SW\\Documents\\projects\\wf\\weather_forecast\\venv\\Lib\\site-packages\\xgboost\\core.py\", line 726, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\SW\\Documents\\projects\\wf\\weather_forecast\\venv\\Lib\\site-packages\\xgboost\\sklearn.py\", line 1108, in fit\n",
      "    self._Booster = train(\n",
      "                    ^^^^^^\n",
      "  File \"c:\\Users\\SW\\Documents\\projects\\wf\\weather_forecast\\venv\\Lib\\site-packages\\xgboost\\core.py\", line 726, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\SW\\Documents\\projects\\wf\\weather_forecast\\venv\\Lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"c:\\Users\\SW\\Documents\\projects\\wf\\weather_forecast\\venv\\Lib\\site-packages\\xgboost\\core.py\", line 2100, in update\n",
      "    _check_call(\n",
      "  File \"c:\\Users\\SW\\Documents\\projects\\wf\\weather_forecast\\venv\\Lib\\site-packages\\xgboost\\core.py\", line 284, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 8 for Parameter colsample_bytree exceed bound [0,1]\n",
      "colsample_bytree: Subsample ratio of columns, resample on each tree construction.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "150 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\SW\\Documents\\projects\\wf\\weather_forecast\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\SW\\Documents\\projects\\wf\\weather_forecast\\venv\\Lib\\site-packages\\xgboost\\core.py\", line 726, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\SW\\Documents\\projects\\wf\\weather_forecast\\venv\\Lib\\site-packages\\xgboost\\sklearn.py\", line 1108, in fit\n",
      "    self._Booster = train(\n",
      "                    ^^^^^^\n",
      "  File \"c:\\Users\\SW\\Documents\\projects\\wf\\weather_forecast\\venv\\Lib\\site-packages\\xgboost\\core.py\", line 726, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\SW\\Documents\\projects\\wf\\weather_forecast\\venv\\Lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"c:\\Users\\SW\\Documents\\projects\\wf\\weather_forecast\\venv\\Lib\\site-packages\\xgboost\\core.py\", line 2100, in update\n",
      "    _check_call(\n",
      "  File \"c:\\Users\\SW\\Documents\\projects\\wf\\weather_forecast\\venv\\Lib\\site-packages\\xgboost\\core.py\", line 284, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 16 for Parameter colsample_bytree exceed bound [0,1]\n",
      "colsample_bytree: Subsample ratio of columns, resample on each tree construction.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "150 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\SW\\Documents\\projects\\wf\\weather_forecast\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\SW\\Documents\\projects\\wf\\weather_forecast\\venv\\Lib\\site-packages\\xgboost\\core.py\", line 726, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\SW\\Documents\\projects\\wf\\weather_forecast\\venv\\Lib\\site-packages\\xgboost\\sklearn.py\", line 1108, in fit\n",
      "    self._Booster = train(\n",
      "                    ^^^^^^\n",
      "  File \"c:\\Users\\SW\\Documents\\projects\\wf\\weather_forecast\\venv\\Lib\\site-packages\\xgboost\\core.py\", line 726, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\SW\\Documents\\projects\\wf\\weather_forecast\\venv\\Lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"c:\\Users\\SW\\Documents\\projects\\wf\\weather_forecast\\venv\\Lib\\site-packages\\xgboost\\core.py\", line 2100, in update\n",
      "    _check_call(\n",
      "  File \"c:\\Users\\SW\\Documents\\projects\\wf\\weather_forecast\\venv\\Lib\\site-packages\\xgboost\\core.py\", line 284, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 32 for Parameter colsample_bytree exceed bound [0,1]\n",
      "colsample_bytree: Subsample ratio of columns, resample on each tree construction.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    params = {\n",
    "        'max_depth':[8, 16, 32],\n",
    "        'min_child_weight':[2, 4, 8, 16, 32],\n",
    "        'colsample_bytree':[2, 4, 8, 16, 32]\n",
    "    }\n",
    "    tunning_model = xgboost.XGBRegressor()\n",
    "    xgboost_model = GridSearchCV(\n",
    "        estimator=tunning_model,\n",
    "        param_grid=params,\n",
    "        scoring='r2',\n",
    "        cv=10\n",
    "    )\n",
    "    xgboost_result = xgboost_model.fit(X_train_scaled, y_train)\n",
    "    xgboost_best_model = xgboost_result.best_estimator_\n",
    "    xgboost_predictions = xgboost_best_model.predict(X_test_scaled)\n",
    "\n",
    "    data_to_save = {\n",
    "        Model.MODEL.value: xgboost_best_model,\n",
    "        Data.TRAIN_INPUT_DATA.value: X_train_scaled,\n",
    "        Data.TRAIN_OUTPUT_DATA.value: X_test_scaled,\n",
    "        Data.VALID_INPUT_DATA.value: [],\n",
    "        Data.VALID_OUTPUT_DATA.value: [],\n",
    "        Data.TEST_INPUT_DATA.value: y_train,\n",
    "        Data.TEST_OUTPUT_DATA.value: y_test,\n",
    "        Data.PREDICTED_OUTPUT_DATA.value: xgboost_predictions,\n",
    "        Rmse.BEST_RMSE: math.sqrt(mean_squared_error(xgboost_predictions, y_test)),\n",
    "        Date.DATE.value: date_df,\n",
    "    }\n",
    "\n",
    "    path = f'result_model/{area}'\n",
    "    file_path = f'{path}/Xgboost_model_with_{area}.pkl'\n",
    "\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "    with open(file_path, 'wb') as f:\n",
    "        pickle.dump(data_to_save, f)\n",
    "except Exception as e:\n",
    "    print(f\"오류 발생: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
